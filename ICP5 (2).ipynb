{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u6r5tvrHJTAp",
        "outputId": "17dccd68-e9f1-428d-95a8-189c7b803058"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv = '/content/gdrive/My Drive/diabetes.csv'"
      ],
      "metadata": {
        "id": "cjj6K5xLL62U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:, 0:8], dataset[:, 8], test_size=0.25, random_state=87)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(155)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add Dense layers with 'relu' activation for hidden layers\n",
        "model.add(Dense(20, input_dim=8, activation='relu'))  # First hidden layer\n",
        "model.add(Dense(15, activation='relu'))  # Second hidden layer\n",
        "model.add(Dense(10, activation='relu'))  # Third hidden layer\n",
        "\n",
        "# Add output layer with 'sigmoid' activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model using binary crossentropy and adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "model_fitted = model.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "# Print model summary and evaluate accuracy on the test set\n",
        "print(model.summary())\n",
        "print(model.evaluate(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zbY8mbj7L9N8",
        "outputId": "8ad13ec9-92d5-46b2-c8ac-4fe493467697"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.3190 - loss: 5.7087\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4067 - loss: 2.3054 \n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4371 - loss: 1.3191 \n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5272 - loss: 1.0544 \n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5203 - loss: 0.8864 \n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5173 - loss: 0.8031 \n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5214 - loss: 0.7698 \n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5571 - loss: 0.6963 \n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5678 - loss: 0.6779 \n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5532 - loss: 0.6569 \n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5772 - loss: 0.6605 \n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5038 - loss: 0.6706 \n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5560 - loss: 0.6441 \n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5297 - loss: 0.6524 \n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5507 - loss: 0.6466 \n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5692 - loss: 0.6386 \n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6033 - loss: 0.6139 \n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6284 - loss: 0.6236 \n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6729 - loss: 0.6436 \n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6860 - loss: 0.6442 \n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7245 - loss: 0.5918 \n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7095 - loss: 0.6080 \n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7321 - loss: 0.5977 \n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7234 - loss: 0.5963  \n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7408 - loss: 0.5698  \n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6980 - loss: 0.6211 \n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6840 - loss: 0.6194 \n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7188 - loss: 0.6051 \n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7462 - loss: 0.5701 \n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7327 - loss: 0.5754 \n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7013 - loss: 0.6131 \n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7019 - loss: 0.6206  \n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7502 - loss: 0.5401 \n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7264 - loss: 0.5833 \n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7340 - loss: 0.5827 \n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7660 - loss: 0.5447  \n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7393 - loss: 0.5799  \n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7176 - loss: 0.5618 \n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7424 - loss: 0.5797 \n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7393 - loss: 0.5519 \n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7300 - loss: 0.5793 \n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7427 - loss: 0.5491 \n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7539 - loss: 0.5540 \n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7690 - loss: 0.5501 \n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7384 - loss: 0.5427 \n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7378 - loss: 0.5531 \n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7457 - loss: 0.5522 \n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7155 - loss: 0.5701  \n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6924 - loss: 0.5807  \n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7113 - loss: 0.5718 \n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7524 - loss: 0.5103 \n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7496 - loss: 0.5274 \n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7143 - loss: 0.5703 \n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7197 - loss: 0.5559 \n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7173 - loss: 0.5576 \n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7615 - loss: 0.5316 \n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7287 - loss: 0.5506 \n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7461 - loss: 0.5225 \n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7556 - loss: 0.5372 \n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7567 - loss: 0.5275 \n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7489 - loss: 0.5255 \n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7605 - loss: 0.5334 \n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7875 - loss: 0.5061 \n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7417 - loss: 0.5325 \n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7579 - loss: 0.5309 \n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7366 - loss: 0.5271 \n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7525 - loss: 0.5385 \n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7637 - loss: 0.5188 \n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7603 - loss: 0.5020 \n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7391 - loss: 0.5333 \n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7824 - loss: 0.4815 \n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7692 - loss: 0.5031 \n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7294 - loss: 0.5682 \n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7502 - loss: 0.5285 \n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7369 - loss: 0.5336 \n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7692 - loss: 0.5219 \n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7408 - loss: 0.5452 \n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7461 - loss: 0.5277  \n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7776 - loss: 0.4981 \n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7296 - loss: 0.5524  \n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7573 - loss: 0.5163 \n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7412 - loss: 0.5288 \n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7412 - loss: 0.5460 \n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7534 - loss: 0.5281 \n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7295 - loss: 0.5537 \n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7619 - loss: 0.5079 \n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7474 - loss: 0.4902 \n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7400 - loss: 0.5420 \n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7941 - loss: 0.4994 \n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7542 - loss: 0.5333 \n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7308 - loss: 0.5384 \n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7535 - loss: 0.5134 \n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7440 - loss: 0.5140  \n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7574 - loss: 0.5116 \n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7535 - loss: 0.5300 \n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7358 - loss: 0.5309 \n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7353 - loss: 0.5178 \n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7446 - loss: 0.5244 \n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7546 - loss: 0.5112 \n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7265 - loss: 0.5301 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m180\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m315\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,000\u001b[0m (7.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> (7.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m666\u001b[0m (2.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">666</span> (2.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,334\u001b[0m (5.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,334</span> (5.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7188 - loss: 0.5526  \n",
            "[0.5714862942695618, 0.7083333134651184]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load dataset\n",
        "dataset = pd.read_csv(path_to_csv, header=None).values\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset[:, 0:8], dataset[:, 8], test_size=0.25, random_state=87)\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(155)\n",
        "\n",
        "# Create a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Add Dense layers with 'relu' activation for hidden layers\n",
        "model.add(Dense(20, input_dim=8, activation='relu'))  # First hidden layer\n",
        "model.add(Dense(15, activation='relu'))  # Second hidden layer\n",
        "model.add(Dense(10, activation='relu'))  # Third hidden layer\n",
        "\n",
        "# Add output layer with 'sigmoid' activation\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model using binary crossentropy and adam optimizer\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "# Train the model\n",
        "model_fitted = model.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "# Print model summary and evaluate accuracy on the test set\n",
        "print(model.summary())\n",
        "print(model.evaluate(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tw6IDM0kMQlM",
        "outputId": "ced09e84-d997-45d5-a0f4-959b41136530"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - acc: 0.6069 - loss: 2.6103\n",
            "Epoch 2/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.4098 - loss: 1.3969 \n",
            "Epoch 3/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.4338 - loss: 1.1178 \n",
            "Epoch 4/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6133 - loss: 0.8093 \n",
            "Epoch 5/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5246 - loss: 0.8328 \n",
            "Epoch 6/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5479 - loss: 0.7467 \n",
            "Epoch 7/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6121 - loss: 0.7069 \n",
            "Epoch 8/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.5838 - loss: 0.7007 \n",
            "Epoch 9/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6276 - loss: 0.7060 \n",
            "Epoch 10/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6822 - loss: 0.6447  \n",
            "Epoch 11/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6323 - loss: 0.6508  \n",
            "Epoch 12/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6680 - loss: 0.6438 \n",
            "Epoch 13/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6713 - loss: 0.6273 \n",
            "Epoch 14/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6869 - loss: 0.6233 \n",
            "Epoch 15/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6623 - loss: 0.6170  \n",
            "Epoch 16/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6733 - loss: 0.6254 \n",
            "Epoch 17/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6852 - loss: 0.6094 \n",
            "Epoch 18/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6919 - loss: 0.6023 \n",
            "Epoch 19/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7038 - loss: 0.6025 \n",
            "Epoch 20/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7065 - loss: 0.5702 \n",
            "Epoch 21/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7127 - loss: 0.5799 \n",
            "Epoch 22/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7280 - loss: 0.5637 \n",
            "Epoch 23/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6904 - loss: 0.5891  \n",
            "Epoch 24/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7165 - loss: 0.5772 \n",
            "Epoch 25/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7032 - loss: 0.5721 \n",
            "Epoch 26/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6943 - loss: 0.6148 \n",
            "Epoch 27/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6907 - loss: 0.5895 \n",
            "Epoch 28/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7139 - loss: 0.5606 \n",
            "Epoch 29/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7101 - loss: 0.5705 \n",
            "Epoch 30/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7075 - loss: 0.5848 \n",
            "Epoch 31/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7040 - loss: 0.5891 \n",
            "Epoch 32/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7141 - loss: 0.5516 \n",
            "Epoch 33/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7080 - loss: 0.5693 \n",
            "Epoch 34/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7145 - loss: 0.5758 \n",
            "Epoch 35/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7288 - loss: 0.5572 \n",
            "Epoch 36/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7356 - loss: 0.5421 \n",
            "Epoch 37/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7327 - loss: 0.5439 \n",
            "Epoch 38/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6894 - loss: 0.5916 \n",
            "Epoch 39/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6899 - loss: 0.5667  \n",
            "Epoch 40/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7233 - loss: 0.5868 \n",
            "Epoch 41/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6997 - loss: 0.5847 \n",
            "Epoch 42/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7397 - loss: 0.5511 \n",
            "Epoch 43/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6904 - loss: 0.5578 \n",
            "Epoch 44/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7027 - loss: 0.5815 \n",
            "Epoch 45/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7123 - loss: 0.5803 \n",
            "Epoch 46/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7184 - loss: 0.5542 \n",
            "Epoch 47/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7063 - loss: 0.5961 \n",
            "Epoch 48/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6950 - loss: 0.5709 \n",
            "Epoch 49/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7237 - loss: 0.5583 \n",
            "Epoch 50/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7089 - loss: 0.5568  \n",
            "Epoch 51/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7244 - loss: 0.5613 \n",
            "Epoch 52/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7393 - loss: 0.5547  \n",
            "Epoch 53/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7321 - loss: 0.5306 \n",
            "Epoch 54/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6965 - loss: 0.5663 \n",
            "Epoch 55/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7224 - loss: 0.5497 \n",
            "Epoch 56/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7690 - loss: 0.5140 \n",
            "Epoch 57/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7089 - loss: 0.5548 \n",
            "Epoch 58/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7242 - loss: 0.5640 \n",
            "Epoch 59/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7055 - loss: 0.5518 \n",
            "Epoch 60/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7469 - loss: 0.5266 \n",
            "Epoch 61/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7345 - loss: 0.5327 \n",
            "Epoch 62/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7365 - loss: 0.5531 \n",
            "Epoch 63/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7314 - loss: 0.5246 \n",
            "Epoch 64/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7077 - loss: 0.5969  \n",
            "Epoch 65/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7405 - loss: 0.5322 \n",
            "Epoch 66/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7223 - loss: 0.5392 \n",
            "Epoch 67/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7577 - loss: 0.5323 \n",
            "Epoch 68/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7115 - loss: 0.5403 \n",
            "Epoch 69/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7405 - loss: 0.5426 \n",
            "Epoch 70/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7508 - loss: 0.5392 \n",
            "Epoch 71/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7321 - loss: 0.5465 \n",
            "Epoch 72/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7093 - loss: 0.5626 \n",
            "Epoch 73/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7263 - loss: 0.5426 \n",
            "Epoch 74/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7489 - loss: 0.5164 \n",
            "Epoch 75/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7499 - loss: 0.5568 \n",
            "Epoch 76/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7441 - loss: 0.5123 \n",
            "Epoch 77/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7385 - loss: 0.5295 \n",
            "Epoch 78/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7137 - loss: 0.5510 \n",
            "Epoch 79/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7633 - loss: 0.5052 \n",
            "Epoch 80/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7736 - loss: 0.5236 \n",
            "Epoch 81/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7560 - loss: 0.5183 \n",
            "Epoch 82/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7671 - loss: 0.5163 \n",
            "Epoch 83/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7430 - loss: 0.5451  \n",
            "Epoch 84/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7403 - loss: 0.5393 \n",
            "Epoch 85/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.6915 - loss: 0.5915 \n",
            "Epoch 86/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7332 - loss: 0.5112 \n",
            "Epoch 87/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7323 - loss: 0.5400 \n",
            "Epoch 88/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7528 - loss: 0.5088 \n",
            "Epoch 89/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7336 - loss: 0.5272 \n",
            "Epoch 90/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7479 - loss: 0.5780  \n",
            "Epoch 91/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7181 - loss: 0.5381 \n",
            "Epoch 92/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7552 - loss: 0.5041 \n",
            "Epoch 93/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7576 - loss: 0.5472 \n",
            "Epoch 94/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.7219 - loss: 0.5473 \n",
            "Epoch 95/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7581 - loss: 0.5035 \n",
            "Epoch 96/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7773 - loss: 0.4969 \n",
            "Epoch 97/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7322 - loss: 0.5323 \n",
            "Epoch 98/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7719 - loss: 0.4965 \n",
            "Epoch 99/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7569 - loss: 0.5068  \n",
            "Epoch 100/100\n",
            "\u001b[1m18/18\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 0.7498 - loss: 0.5204 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m180\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                  │             \u001b[38;5;34m315\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m11\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">180</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">315</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,000\u001b[0m (7.82 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,000</span> (7.82 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m666\u001b[0m (2.60 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">666</span> (2.60 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m1,334\u001b[0m (5.21 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,334</span> (5.21 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 0.6621 - loss: 0.5916  \n",
            "[0.5897912383079529, 0.671875]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv1 = '/content/gdrive/My Drive/breastcancer.csv'"
      ],
      "metadata": {
        "id": "8-3smp5TMZt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation\n",
        "\n",
        "# load dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "dataset = pd.read_csv(path_to_csv1, header=None).values\n",
        "\n",
        "X = dataset[1:, 2:-1]  # Features\n",
        "Y = dataset[1:, -1]   # Labels (M or B)\n",
        "\n",
        "# Convert labels to binary format\n",
        "Y = np.where(Y == 'M', 1, 0)  # M -> 1, B -> 0\n",
        "\n",
        "#Convert to numeric\n",
        "X = X.astype(np.float64) # Convert X to numeric\n",
        "\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y,\n",
        "                                                    test_size=0.25, random_state=87)\n",
        "\n",
        "\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential() # create model\n",
        "my_first_nn.add(Dense(20, input_dim=30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(30, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(40, activation='relu')) # hidden layer\n",
        "my_first_nn.add(Dense(50, activation='relu')) # hidden layer\n",
        "\n",
        "my_first_nn.add(Dense(1, activation='sigmoid')) # output layer\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100,\n",
        "                                     initial_epoch=0)\n",
        "print(my_first_nn.summary())\n",
        "print(my_first_nn.evaluate(X_test,Y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "L1cbIhS0MxXM",
        "outputId": "f5801f28-43bb-4bf7-f297-4667c5a1e099"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - acc: 0.4632 - loss: 21.6955    \n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.5355e-18 \n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.7323e-21 \n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.4181e-23 \n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.3417e-23  \n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.4529e-23 \n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.7339e-24 \n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.4758e-23 \n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.2038e-23 \n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.3121e-24 \n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.3365e-23 \n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.9069e-24 \n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.3942e-23  \n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.7827e-23 \n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 8.3061e-24 \n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.7197e-23  \n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 7.8483e-24 \n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.4026e-23 \n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.8664e-23 \n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.2286e-24 \n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.1670e-23 \n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3073e-23 \n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0445e-23 \n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3174e-23 \n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.9787e-23 \n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.5664e-24 \n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.8833e-23 \n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.1647e-23 \n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.2143e-23 \n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.5648e-23 \n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.7845e-23 \n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.7683e-24 \n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.6667e-23 \n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 8.4303e-24 \n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.4461e-23 \n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.6889e-23 \n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 4.3336e-23  \n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 4.3806e-23  \n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.8012e-24 \n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 7.5741e-24  \n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 9.9436e-24 \n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 3.4460e-23 \n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.4380e-23 \n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.1865e-23  \n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 2.7703e-23 \n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 5.0736e-24 \n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.1375e-23 \n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.8679e-24 \n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.6588e-23 \n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 7.7012e-24 \n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 8.1386e-24 \n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.4281e-23  \n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.1816e-23  \n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 6.1814e-23  \n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.4491e-23 \n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 1.8226e-23 \n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 2.8015e-23 \n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 7.6719e-24  \n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 9.0052e-24 \n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.5264e-24 \n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - acc: 1.0000 - loss: 6.2031e-24\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 8.4618e-24 \n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 1.1060e-23 \n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.7328e-24 \n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0989e-23  \n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.9461e-24 \n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.1563e-23 \n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.4600e-23 \n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.7841e-23 \n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.6593e-23 \n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.9723e-23 \n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3922e-23 \n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.3356e-24  \n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.2959e-23  \n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0094e-23 \n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.0033e-23 \n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.1748e-23 \n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.4641e-23 \n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.4753e-23 \n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.9713e-23 \n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3618e-23 \n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.4926e-23 \n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.4703e-23 \n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.9802e-24 \n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.4335e-23 \n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.4886e-23 \n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.4854e-23 \n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.7824e-23  \n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.7138e-24 \n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.1187e-23 \n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.4328e-24 \n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.3039e-23 \n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.6697e-23  \n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3393e-23 \n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.2194e-24 \n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.2559e-23 \n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.1150e-23 \n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.9519e-23 \n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.4001e-23 \n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.4392e-23  \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m620\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m630\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │           \u001b[38;5;34m1,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,775\u001b[0m (53.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,775</span> (53.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,591\u001b[0m (17.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,591</span> (17.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,184\u001b[0m (35.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,184</span> (35.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.2542e-19  \n",
            "[2.4141023193055175e-19, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Load dataset (ensure to replace 'path_to_csv1' with the actual path to your CSV file)\n",
        "dataset = pd.read_csv(path_to_csv1, header=None).values\n",
        "\n",
        "# Features and Labels extraction\n",
        "X = dataset[1:, 2:-1]  # Assuming your features are from the 3rd column to the second last\n",
        "Y = dataset[1:, -1]    # Labels (M or B)\n",
        "\n",
        "# Convert labels to binary format\n",
        "Y = np.where(Y == 'M', 1, 0)  # M -> 1, B -> 0\n",
        "\n",
        "# Convert features to numeric\n",
        "X = X.astype(np.float64)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.25, random_state=87)\n",
        "\n",
        "# Normalize the data\n",
        "sc = StandardScaler()\n",
        "X_train = sc.fit_transform(X_train)\n",
        "X_test = sc.transform(X_test)\n",
        "\n",
        "# Create and compile the model\n",
        "np.random.seed(155)\n",
        "my_first_nn = Sequential()\n",
        "my_first_nn.add(Dense(20, input_dim=X_train.shape[1], activation='relu'))  # Input and hidden layer\n",
        "my_first_nn.add(Dense(30, activation='relu'))  # Hidden layer\n",
        "my_first_nn.add(Dense(40, activation='relu'))  # Hidden layer\n",
        "my_first_nn.add(Dense(50, activation='relu'))  # Hidden layer\n",
        "my_first_nn.add(Dense(1, activation='sigmoid'))  # Output layer\n",
        "\n",
        "my_first_nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
        "\n",
        "# Fit the model\n",
        "my_first_nn_fitted = my_first_nn.fit(X_train, Y_train, epochs=100, initial_epoch=0)\n",
        "\n",
        "# Model summary\n",
        "print(my_first_nn.summary())\n",
        "\n",
        "# Model evaluation\n",
        "print(my_first_nn.evaluate(X_test, Y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cdnIA9e3OhYK",
        "outputId": "3f394e82-fe90-4af0-933f-4da582be03e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - acc: 0.2897 - loss: 0.7786    \n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 0.4263 \n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 0.1664 \n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 0.0396 \n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - acc: 1.0000 - loss: 0.0133\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - acc: 1.0000 - loss: 0.0063 \n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 0.0037 \n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 0.0023 \n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 0.0018 \n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 0.0016 \n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 9.3270e-04 \n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 0.0011 \n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 0.0010 \n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.6782e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.2956e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.0933e-04 \n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.1689e-04 \n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.1724e-04 \n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.5264e-04 \n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.0318e-04 \n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.5145e-04 \n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.2682e-04 \n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.0170e-04 \n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.3490e-04 \n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.2762e-04 \n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.4767e-04 \n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.1058e-04 \n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 8.7684e-05 \n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.5570e-05 \n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0252e-04 \n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.4525e-05 \n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0625e-04 \n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.5004e-05 \n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.0934e-05 \n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.3536e-05 \n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.4080e-05 \n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.5930e-05 \n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.4563e-05 \n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.4467e-05 \n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 3.2966e-05 \n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.0412e-05  \n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.8139e-05  \n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 3.7831e-05 \n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.2630e-05 \n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.1653e-05 \n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.7575e-05 \n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.0681e-05 \n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.7836e-05 \n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.4274e-05  \n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.9887e-05 \n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.4160e-05 \n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.3795e-05 \n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.9672e-05 \n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 2.0558e-05 \n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.2282e-05 \n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.0298e-05 \n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 2.1414e-05 \n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.1045e-05 \n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.5833e-06 \n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.2424e-05 \n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.4807e-06 \n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.9724e-05 \n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.7996e-05 \n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.2692e-05 \n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.3232e-05 \n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.0194e-05 \n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.8407e-06 \n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.3721e-05 \n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.7360e-06 \n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.1026e-05 \n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 8.8767e-06 \n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.6110e-06 \n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 1.0805e-05 \n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.2086e-06 \n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.8259e-06 \n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 1.1085e-05 \n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.4063e-06 \n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.6654e-06 \n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.1753e-06 \n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.7801e-06 \n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 7.5057e-06 \n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 5.8740e-06  \n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 5.1262e-06  \n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 8.9123e-06 \n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 9.8815e-06 \n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.3333e-06 \n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 9.3847e-06 \n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.2030e-06  \n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.3796e-06 \n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.5705e-06 \n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.0552e-06 \n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.5655e-06 \n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 5.0981e-06 \n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 4.8528e-06 \n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 6.0609e-06 \n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 4.0042e-06  \n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 4.8173e-06 \n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.0151e-06 \n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 6.1184e-06 \n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - acc: 1.0000 - loss: 2.8973e-06 \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_3\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_3\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_13 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │             \u001b[38;5;34m620\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │             \u001b[38;5;34m630\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m40\u001b[0m)                  │           \u001b[38;5;34m1,240\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m)                  │           \u001b[38;5;34m2,050\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m51\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">620</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">630</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_15 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,240</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,050</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">51</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,775\u001b[0m (53.81 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,775</span> (53.81 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,591\u001b[0m (17.93 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,591</span> (17.93 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,184\u001b[0m (35.88 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,184</span> (35.88 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - acc: 1.0000 - loss: 7.9473e-06  \n",
            "[7.064252713462338e-06, 1.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_csv1 = '/content/gdrive/My Drive/breastcancer.csv'"
      ],
      "metadata": {
        "id": "nlYYBZkKOpbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the dataset\n",
        "data = pd.read_csv('/content/gdrive/My Drive/breastcancer.csv')\n",
        "\n",
        "# Print the column names to help you choose the correct column\n",
        "print(data.columns)\n",
        "\n",
        "# Replace 'diagnosis' with the actual column name for labels, if needed\n",
        "label_column = 'diagnosis'  # Example: 'diagnosis' for benign/malignant\n",
        "\n",
        "# Count the occurrences of each class\n",
        "label_counts = data[label_column].value_counts()\n",
        "\n",
        "# Create a bar graph\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(label_counts.index, label_counts.values, color=['#ff9999', '#66b3ff'])\n",
        "\n",
        "# Add title and labels\n",
        "plt.title(f'Distribution of {label_column}')\n",
        "plt.xlabel('Class')\n",
        "plt.ylabel('Count')\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "cSrFp40dPET4",
        "outputId": "afae7d3b-4e5f-45fc-f6e9-9c3648a25340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 743
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['id', 'diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',\n",
            "       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',\n",
            "       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',\n",
            "       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',\n",
            "       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',\n",
            "       'fractal_dimension_se', 'radius_worst', 'texture_worst',\n",
            "       'perimeter_worst', 'area_worst', 'smoothness_worst',\n",
            "       'compactness_worst', 'concavity_worst', 'concave points_worst',\n",
            "       'symmetry_worst', 'fractal_dimension_worst', 'Unnamed: 32'],\n",
            "      dtype='object')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}